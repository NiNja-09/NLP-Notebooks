{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization\n",
        "Lemmatization is a text normalization technique used in natural language processing (NLP) to reduce words to their base or dictionary form, called the lemma. Unlike stemming, which simply removes suffixes or prefixes from words to derive their root forms, lemmatization considers the context of words and their morphological analysis to ensure that the resulting lemma is a valid word.\n",
        "\n",
        "Original words: \"happier\", \"happiest\", \"happy\"\n",
        "\n",
        "Lemmatized form: \"happy\"\n",
        "\n",
        "### Different types of lemmatizers used commonly:\n",
        "\n",
        "WordNet Lemmatizer: Based on the WordNet lexical database, this lemmatizer maps words to their corresponding lemmas using a predefined set of rules and mappings stored in WordNet.\n",
        "\n",
        "SpaCy Lemmatizer: An open-source NLP library that provides lemmatization capabilities along with other text processing functionalities.\n",
        "\n",
        "NLTK Lemmatizer: The Natural Language Toolkit (NLTK) library for Python includes a lemmatizer module that offers lemmatization functionalities.\n",
        "\n",
        "TextBlob Lemmatizer: TextBlob, a Python library built on NLTK and Pattern, also provides lemmatization capabilities.\n",
        "\n",
        "### Drawbacks of lemmatization:\n",
        "\n",
        "Computational Complexity: Lemmatization can be computationally more expensive compared to stemming, as it requires access to a dictionary or lexical database and involves morphological analysis.\n",
        "\n",
        "Dependency on Language Resources: Lemmatization often relies on language-specific resources such as dictionaries or lexicons, making it less suitable for languages with limited or incomplete linguistic resources.\n",
        "\n",
        "Ambiguity Resolution: Lemmatization may struggle with disambiguating words with multiple meanings or forms, leading to inaccuracies in lemma assignment.\n",
        "\n",
        "### Advantages of lemmatization over stemming:\n",
        "\n",
        "Better Accuracy: Lemmatization produces valid words (lemmas) that are present in the language's vocabulary, ensuring better accuracy in word normalization compared to stemming.\n",
        "\n",
        "Semantic Preservation: Lemmatization preserves the semantic meaning of words by reducing them to their base forms, which helps in maintaining the interpretability of text data.\n",
        "\n",
        "Contextual Analysis: Lemmatization considers the context of words and their morphological analysis, leading to more accurate normalization compared to the rule-based approach of stemming.\n",
        "\n",
        "### Usage:\n",
        "Lemmatization is typically used in applications where preserving the semantic meaning of words is crucial, such as machine translation, sentiment analysis, or question answering systems. It is preferred over stemming when more accurate word normalization is required, as lemmatization produces valid lemmas that are present in the language's vocabulary."
      ],
      "metadata": {
        "id": "N9qJlelhWFJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WordNet Lemmatizer"
      ],
      "metadata": {
        "id": "fVKAqJ2veAgo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbV-KSILWBRo",
        "outputId": "8b9ac427-2216-4471-f765-541b0e2feda0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"running\", \"runs\", \"ran\", \"runner\",\n",
        "                      \"better\", \"best\", \"good\",\n",
        "                      \"happier\", \"happiest\", \"happy\",\n",
        "                      \"jumps\", \"jumping\"]"
      ],
      "metadata": {
        "id": "-wbEpAzbc9Gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wnl = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "lZSlG_PJdJuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word+\"--->\"+wnl.lemmatize(word,pos='v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBokpyS2dN6c",
        "outputId": "b4e9f4c5-a697-4502-fe44-f8e5c6840951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running--->run\n",
            "runs--->run\n",
            "ran--->run\n",
            "runner--->runner\n",
            "better--->better\n",
            "best--->best\n",
            "good--->good\n",
            "happier--->happier\n",
            "happiest--->happiest\n",
            "happy--->happy\n",
            "jumps--->jump\n",
            "jumping--->jump\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word+\"--->\"+wnl.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3LwGi5RdZbE",
        "outputId": "2177e76c-e30e-4ac4-82ca-069b7c6c73bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running--->running\n",
            "runs--->run\n",
            "ran--->ran\n",
            "runner--->runner\n",
            "better--->better\n",
            "best--->best\n",
            "good--->good\n",
            "happier--->happier\n",
            "happiest--->happiest\n",
            "happy--->happy\n",
            "jumps--->jump\n",
            "jumping--->jumping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# spaCy Lemmatizer"
      ],
      "metadata": {
        "id": "76ReOyLieHam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "2PGtqZ4yd74s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "dBxer2Dbe1Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"running\", \"runs\", \"ran\", \"runner\",\n",
        "                      \"better\", \"best\", \"good\",\n",
        "                      \"happier\", \"happiest\", \"happy\",\n",
        "                      \"jumps\", \"jumping\"]"
      ],
      "metadata": {
        "id": "wSUhLSB-fCA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "    doc = nlp(word)    # Process the word using SpaCy\n",
        "    lemma = doc[0].lemma_\n",
        "    print(word + \" ---> \" + lemma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2F5jizPewDE",
        "outputId": "67d23322-5333-4ac3-8559-b7fc68b263b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running ---> run\n",
            "runs ---> run\n",
            "ran ---> run\n",
            "runner ---> runner\n",
            "better ---> well\n",
            "best ---> good\n",
            "good ---> good\n",
            "happier ---> happy\n",
            "happiest ---> happy\n",
            "happy ---> happy\n",
            "jumps ---> jump\n",
            "jumping ---> jump\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pNVz9OKGe8fa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}