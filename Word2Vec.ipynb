{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec\n",
        "Word2Vec is a popular technique in natural language processing (NLP) used to convert words into dense vector representations, also known as word embeddings. These word embeddings capture semantic relationships between words, making them valuable in various NLP tasks like sentiment analysis, text classification, machine translation, and more. There are two main architectures for Word2Vec: Continuous Bag of Words (CBOW) and Skip-gram.\n",
        "\n",
        "### Continuous Bag of Words (CBOW):\n",
        "In the CBOW architecture, the model predicts the current word given a context. The \"context\" refers to the surrounding words within a fixed window size. The model takes input as a bag of context words and predicts the target word.\n",
        "CBOW performs better on smaller datasets.\n",
        "\n",
        "Here's how CBOW works:\n",
        "\n",
        "Input Layer: It consists of the context words encoded as one-hot vectors.\n",
        "\n",
        "Projection Layer: It maps one-hot encoded vectors to distributed representation vectors (word embeddings). This layer is often referred to as the embedding layer.\n",
        "\n",
        "Hidden Layer: This layer processes the distributed representations of context words.\n",
        "\n",
        "Output Layer: It produces a probability distribution over the vocabulary. The target word is predicted based on this distribution.\n",
        "\n",
        "For example, consider the sentence \"The cat sits on the mat.\" If we set a window size of 2, and we want to predict the target word \"sits\", the context words would be \"The\", \"cat\", \"on\", and \"the\". The CBOW model would try to predict \"sits\" given these context words.\n",
        "\n",
        "### Skip-gram:\n",
        "Skip-gram is the reverse of CBOW. It predicts the context words given a target word. Instead of predicting the target word from the context, Skip-gram predicts surrounding words given a target word. The model learns to maximize the probability of context words given the target word. Skip-gram is suitable for larger datasets and is more effective at capturing semantic relationships between words.\n",
        "\n",
        "Input Layer: It consists of the target word encoded as a one-hot vector.\n",
        "\n",
        "Projection Layer: Similar to CBOW, it maps one-hot encoded vectors to distributed representation vectors (word embeddings).\n",
        "\n",
        "Hidden Layer: This layer processes the distributed representation of the target word.\n",
        "\n",
        "Output Layer: Produces a probability distribution over the vocabulary. Each output neuron corresponds to a word in the vocabulary, and the model aims to predict the probability of each word being a context word given the target word.\n",
        "\n",
        "Using the same example sentence, if the target word is \"sits\", Skip-gram would try to predict \"The\", \"cat\", \"on\", and \"the\" as context words.\n",
        "\n",
        "### Advantages:\n",
        "\n",
        "Semantic Similarity: Word embeddings capture semantic relationships, allowing for measuring similarity between words.\n",
        "\n",
        "Dimensionality Reduction: Word embeddings reduce the dimensionality of the data while preserving important semantic information.\n",
        "\n",
        "Efficiency: Once trained, Word2Vec models can quickly generate word embeddings for large vocabularies.\n",
        "\n",
        "### Disadvantages:\n",
        "\n",
        "Requires Large Corpus: Word2Vec requires a large corpus of text data for training to learn meaningful embeddings.\n",
        "\n",
        "Out-of-vocabulary Words: Words not seen during training will not have embeddings, causing issues for rare or misspelled words.\n",
        "\n",
        "Contextual Information: Word2Vec ignores contextual information, which can limit its effectiveness in certain tasks where context plays a crucial role.\n",
        "\n",
        "Fixed Context Window: The choice of context window size can impact the quality of embeddings, and there's no universal best window size for all tasks.\n",
        "\n",
        "### Usage:\n",
        "Word2Vec is used in various NLP tasks such as sentiment analysis, document clustering, machine translation, and information retrieval. It enables tasks like synonym detection, analogy completion, and word similarity calculations."
      ],
      "metadata": {
        "id": "Wje1RFWT8kdR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IS9IxFp4NVck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ceeebb8-2c42-41f8-f891-2866897ee8b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The quick brown fox jumps over the lazy dog.\""
      ],
      "metadata": {
        "id": "YrWqYz3LLdLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text using NLTK\n",
        "tokens = word_tokenize(text.lower())\n",
        "\n",
        "# Remove stopwords using NLTK\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word not in stop_words]"
      ],
      "metadata": {
        "id": "wtF0GC2hLdP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Word2Vec model using Gensim\n",
        "model = Word2Vec([filtered_tokens], vector_size=100, window=5, min_count=1, sg=1) #  CBOW (sg=0) and Skip-gram (sg=1) # window = 5 represents the context or the words taken into consideration during training.\n",
        "model1 = Word2Vec([filtered_tokens], vector_size=100, window=5, min_count=1, sg=0) # vector_size = 100 represents each word will be represented as a 100-dimensional vector"
      ],
      "metadata": {
        "id": "5uLdjhwcLdmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get word embeddings\n",
        "word_embeddings = model.wv\n",
        "word_embeddings1 = model1.wv"
      ],
      "metadata": {
        "id": "BOpNHDppLdqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access word embeddings\n",
        "print(word_embeddings['fox'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjItc7FDLdtu",
        "outputId": "c0c11091-839b-47cb-ebe6-d062c71ea476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.00713902  0.00124103 -0.00717672 -0.00224462  0.0037193   0.00583312\n",
            "  0.00119818  0.00210273 -0.00411039  0.00722533 -0.00630704  0.00464722\n",
            " -0.00821997  0.00203647 -0.00497705 -0.00424769 -0.00310898  0.00565521\n",
            "  0.0057984  -0.00497465  0.00077333 -0.00849578  0.00780981  0.00925729\n",
            " -0.00274233  0.00080022  0.00074665  0.00547788 -0.00860608  0.00058446\n",
            "  0.00686942  0.00223159  0.00112468 -0.00932216  0.00848237 -0.00626413\n",
            " -0.00299237  0.00349379 -0.00077263  0.00141129  0.00178199 -0.0068289\n",
            " -0.00972481  0.00904058  0.00619805 -0.00691293  0.00340348  0.00020606\n",
            "  0.00475375 -0.00711994  0.00402695  0.00434743  0.00995737 -0.00447374\n",
            " -0.00138926 -0.00731732 -0.00969783 -0.00908026 -0.00102275 -0.00650329\n",
            "  0.00484973 -0.00616403  0.00251919  0.00073944 -0.00339215 -0.00097922\n",
            "  0.00997913  0.00914589 -0.00446183  0.00908303 -0.00564176  0.00593092\n",
            " -0.00309722  0.00343175  0.00301723  0.00690046 -0.00237388  0.00877504\n",
            "  0.00758943 -0.00954765 -0.00800821 -0.0076379   0.00292326 -0.00279472\n",
            " -0.00692952 -0.00812826  0.00830918  0.00199049 -0.00932802 -0.00479272\n",
            "  0.00313674 -0.00471321  0.00528084 -0.00423344  0.0026418  -0.00804569\n",
            "  0.00620989  0.00481889  0.00078719  0.00301345]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access word embeddings\n",
        "print(word_embeddings1['fox'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbt7iYJDOE6h",
        "outputId": "1e0d1a1b-daa6-41ea-cd8a-07a0627acaf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.00713902  0.00124103 -0.00717672 -0.00224462  0.0037193   0.00583312\n",
            "  0.00119818  0.00210273 -0.00411039  0.00722533 -0.00630704  0.00464722\n",
            " -0.00821997  0.00203647 -0.00497705 -0.00424769 -0.00310898  0.00565521\n",
            "  0.0057984  -0.00497465  0.00077333 -0.00849578  0.00780981  0.00925729\n",
            " -0.00274233  0.00080022  0.00074665  0.00547788 -0.00860608  0.00058446\n",
            "  0.00686942  0.00223159  0.00112468 -0.00932216  0.00848237 -0.00626413\n",
            " -0.00299237  0.00349379 -0.00077263  0.00141129  0.00178199 -0.0068289\n",
            " -0.00972481  0.00904058  0.00619805 -0.00691293  0.00340348  0.00020606\n",
            "  0.00475375 -0.00711994  0.00402695  0.00434743  0.00995737 -0.00447374\n",
            " -0.00138926 -0.00731732 -0.00969783 -0.00908026 -0.00102275 -0.00650329\n",
            "  0.00484973 -0.00616403  0.00251919  0.00073944 -0.00339215 -0.00097922\n",
            "  0.00997913  0.00914589 -0.00446183  0.00908303 -0.00564176  0.00593092\n",
            " -0.00309722  0.00343175  0.00301723  0.00690046 -0.00237388  0.00877504\n",
            "  0.00758943 -0.00954765 -0.00800821 -0.0076379   0.00292326 -0.00279472\n",
            " -0.00692952 -0.00812826  0.00830918  0.00199049 -0.00932802 -0.00479272\n",
            "  0.00313674 -0.00471321  0.00528084 -0.00423344  0.0026418  -0.00804569\n",
            "  0.00620989  0.00481889  0.00078719  0.00301345]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict similarity between words\n",
        "similarity_score = word_embeddings.similarity('fox', 'dog')\n",
        "print(\"Similarity between 'fox' and 'dog':\", similarity_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9tAjmDrpvf9",
        "outputId": "09589771-df2d-4dcf-8f02-2429301acf29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between 'fox' and 'dog': 0.0045030187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pretrained Model"
      ],
      "metadata": {
        "id": "-l-tGGUBL2Qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "import gensim.downloader as api"
      ],
      "metadata": {
        "id": "k71g7o7iBZ-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Word2Vec model\n",
        "word2vec_model = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "id": "J_3Xz9s8O7hi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "113b9ca6-bad5-4407-fb0e-b86a82dd3454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get embedding for a word\n",
        "word_embedding = word2vec_model['word']\n",
        "print(word_embedding)\n",
        "print(word_embedding.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zNE9EnIBsOt",
        "outputId": "b8024b87-5b97-4297-83b7-abeded407120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 3.59375000e-01  4.15039062e-02  9.03320312e-02  5.46875000e-02\n",
            " -1.47460938e-01  4.76074219e-02 -8.49609375e-02 -2.04101562e-01\n",
            "  3.10546875e-01 -1.05590820e-02 -6.15234375e-02 -1.55273438e-01\n",
            " -1.52343750e-01  8.54492188e-02 -2.70996094e-02  3.84765625e-01\n",
            "  4.78515625e-02  2.58789062e-02  4.49218750e-02 -2.79296875e-01\n",
            "  9.09423828e-03  4.08203125e-01  2.40234375e-01 -3.06640625e-01\n",
            " -1.80664062e-01  4.73632812e-02 -2.63671875e-01  9.08203125e-02\n",
            "  1.37695312e-01 -7.20977783e-04  2.67333984e-02  1.92382812e-01\n",
            " -2.29492188e-02  9.70458984e-03 -7.37304688e-02  4.29687500e-01\n",
            " -7.93457031e-03  1.06445312e-01  2.80761719e-02 -2.29492188e-01\n",
            " -1.91650391e-02 -2.36816406e-02  3.51562500e-02  1.71875000e-01\n",
            " -1.12304688e-01  6.25000000e-02 -1.69921875e-01  1.29882812e-01\n",
            " -1.54296875e-01  1.58203125e-01 -7.76367188e-02  1.78710938e-01\n",
            " -1.72851562e-01  9.96093750e-02  3.94531250e-01  6.44531250e-02\n",
            " -6.83593750e-02 -3.18359375e-01  5.95703125e-02 -1.02539062e-02\n",
            "  9.37500000e-02  8.25195312e-02 -2.52685547e-02  1.09863281e-01\n",
            " -6.73828125e-02 -1.70898438e-01  6.78710938e-02  1.04492188e-01\n",
            " -2.11914062e-01  1.30859375e-01 -1.24573708e-05  1.85546875e-02\n",
            " -1.61132812e-01 -8.00781250e-02  9.42382812e-02 -8.78906250e-02\n",
            "  1.82617188e-01 -2.48718262e-03  8.74023438e-02  1.75781250e-01\n",
            " -2.17285156e-02 -1.96289062e-01  9.52148438e-02 -5.15136719e-02\n",
            "  1.01928711e-02  6.22558594e-02 -2.13867188e-01  2.25585938e-01\n",
            "  2.46093750e-01 -6.12792969e-02  1.74560547e-02 -1.46484375e-01\n",
            "  3.93676758e-03 -1.62109375e-01 -1.10839844e-01  6.88476562e-02\n",
            " -1.83593750e-01  1.13281250e-01  9.08203125e-02 -1.64062500e-01\n",
            " -3.71093750e-01 -5.39550781e-02 -8.66699219e-03 -1.18164062e-01\n",
            " -5.93261719e-02  8.74023438e-02 -1.98242188e-01 -1.36718750e-01\n",
            "  6.39648438e-02 -1.88476562e-01 -2.96875000e-01  6.39648438e-02\n",
            "  2.16796875e-01 -7.71484375e-02  1.13769531e-01  1.96533203e-02\n",
            "  2.31445312e-01  6.59179688e-02  1.02539062e-01 -6.39648438e-02\n",
            " -1.48437500e-01 -5.59082031e-02 -2.43164062e-01  2.71484375e-01\n",
            "  1.83593750e-01  3.06396484e-02 -2.01416016e-02 -1.53320312e-01\n",
            "  7.08007812e-02 -2.35595703e-02 -9.66796875e-02 -2.83203125e-01\n",
            " -2.57568359e-02 -7.42187500e-02 -4.27246094e-02  6.98242188e-02\n",
            " -1.74804688e-01  2.27539062e-01  2.92968750e-01 -1.86767578e-02\n",
            "  2.94921875e-01 -1.12304688e-01  4.85839844e-02 -2.15820312e-01\n",
            "  1.03149414e-02 -1.14257812e-01 -6.39648438e-02  7.27539062e-02\n",
            " -1.47460938e-01 -2.16796875e-01  1.32812500e-01  1.83593750e-01\n",
            " -1.48437500e-01 -1.31835938e-01 -3.73535156e-02  1.19628906e-01\n",
            " -2.01171875e-01  1.00097656e-01 -8.93554688e-02  1.23596191e-03\n",
            "  7.17773438e-02  1.42578125e-01 -3.03955078e-02 -1.89453125e-01\n",
            " -8.88671875e-02  3.83300781e-02 -1.74804688e-01 -3.66210938e-03\n",
            " -2.08007812e-01  8.97216797e-03  2.35351562e-01  1.06933594e-01\n",
            " -2.65625000e-01 -2.16796875e-01  7.08007812e-02  9.08203125e-02\n",
            "  3.00781250e-01 -1.07421875e-01  1.01562500e-01 -6.25000000e-02\n",
            "  1.33789062e-01 -1.62353516e-02  2.50000000e-01 -1.72851562e-01\n",
            "  3.32031250e-01  1.12304688e-01 -1.47705078e-02 -1.04980469e-01\n",
            " -8.05664062e-02  3.30078125e-01  9.32617188e-02 -1.47460938e-01\n",
            " -2.05078125e-01 -7.56835938e-02 -1.04492188e-01  6.25000000e-02\n",
            " -2.02148438e-01 -1.09375000e-01 -8.05664062e-02  5.49316406e-02\n",
            " -8.88671875e-02  5.24902344e-02 -2.23632812e-01  5.17578125e-02\n",
            " -1.83593750e-01 -6.73828125e-02 -9.13085938e-02  1.29882812e-01\n",
            " -2.31933594e-02 -1.04003906e-01  1.79687500e-01  8.34960938e-02\n",
            " -8.78906250e-02 -2.17773438e-01 -6.34765625e-02  1.33789062e-01\n",
            "  1.62109375e-01  2.87109375e-01 -1.14257812e-01  6.05468750e-02\n",
            "  1.49414062e-01 -3.08227539e-03  1.96289062e-01 -8.98437500e-02\n",
            "  1.45507812e-01  1.02539062e-02  1.22070312e-02  3.20312500e-01\n",
            "  1.24511719e-01  1.20849609e-02 -1.78710938e-01  3.71093750e-02\n",
            "  6.98242188e-02  1.62109375e-01  9.86328125e-02 -2.61718750e-01\n",
            "  1.89453125e-01 -2.83203125e-02  4.06250000e-01  3.56445312e-02\n",
            "  3.10058594e-02  2.27050781e-02  1.30859375e-01 -1.05957031e-01\n",
            "  8.69140625e-02 -9.76562500e-02  1.89453125e-01  3.17382812e-02\n",
            "  1.10351562e-01  2.11914062e-01 -1.66992188e-01  1.45263672e-02\n",
            "  1.15234375e-01  1.59179688e-01  9.91210938e-02 -2.40234375e-01\n",
            " -2.34375000e-01  1.74804688e-01  1.20605469e-01 -3.67187500e-01\n",
            " -7.81250000e-02  1.10839844e-01 -3.35937500e-01 -9.81445312e-02\n",
            " -7.47070312e-02 -1.89453125e-01  7.81250000e-02 -2.53906250e-01\n",
            " -6.03027344e-02 -2.46093750e-01 -9.37500000e-02  8.64257812e-02\n",
            "  1.15722656e-01 -1.24511719e-01  1.61132812e-01 -6.03027344e-02\n",
            " -2.47070312e-01 -9.52148438e-02 -4.05273438e-02  2.51953125e-01\n",
            " -1.95312500e-01 -1.31835938e-01  6.88476562e-02  2.67333984e-02\n",
            "  1.03027344e-01  1.05957031e-01 -3.01513672e-02  3.04687500e-01\n",
            " -8.74023438e-02  1.19140625e-01 -1.74560547e-02  8.78906250e-03\n",
            " -1.38671875e-01 -2.85156250e-01  2.29492188e-01 -3.55468750e-01\n",
            "  9.52148438e-03 -4.07714844e-02 -8.88671875e-02 -1.39160156e-02]\n",
            "(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of getting most similar words\n",
        "similar_words = word2vec_model.most_similar('king')\n",
        "for words in similar_words:\n",
        "  print(words)"
      ],
      "metadata": {
        "id": "oNZ4MGfkGJDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9166997-288e-4603-9270-47da9a9c8a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('kings', 0.7138045430183411)\n",
            "('queen', 0.6510956883430481)\n",
            "('monarch', 0.6413194537162781)\n",
            "('crown_prince', 0.6204220056533813)\n",
            "('prince', 0.6159993410110474)\n",
            "('sultan', 0.5864824056625366)\n",
            "('ruler', 0.5797567367553711)\n",
            "('princes', 0.5646552443504333)\n",
            "('Prince_Paras', 0.5432944297790527)\n",
            "('throne', 0.5422105193138123)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TKU5eCkwtrH2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}